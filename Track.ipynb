{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing a Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can actually track the fish, we need to give `cvtracer` some information. You can do this in two steps. \n",
    "1. Enter trial-specific information.\n",
    "2. Initialize a new `Trial` object. This will open a GUI that allows you to identify the tank walls.\n",
    "\n",
    "Once you have entered this information and identified the walls you have prepared the run for tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trial and identify tank walls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import some python libraries including the Trial object from cv-tracer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from cvt.TrAQ.Trial import Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the libraries we need, we can start this trial by entering the following information. Make sure you're entering data specific to this trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_video   = os.path.abspath(\"data/20190208_SF_n20_t1_2325/raw.mp4\")\n",
    "fpath       = os.path.split(raw_video)[0]\n",
    "n           =  20\n",
    "t           = \"SF\"\n",
    "date        = \"20190208\" #YYYYMMDD\n",
    "fps         =  30\n",
    "tank_radius =  55.5 #cm\n",
    "t_start     =   0 #sec\n",
    "t_end       =  60 #sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can initialize a trial by running the next block of code. This creates a Trial object that you will be modifying as you add tracks from the run. This will be saved as 'trial.pik'.\n",
    "\n",
    "1. Upon initializing the `Trial` object, you will be presented a simple Graphical User Interface (GUI). It should show you an image from the video you're going to track. \n",
    "\n",
    "2. Using the GUI, you will identify walls by clicking on three points that fall at the very edge of the water. Ideally these will be spaced far away from each other on the edge of the arena. If you make a mistake, just keep clicking until you have three green points that look good (old ones will turn red).\n",
    "\n",
    "3. Once three good points have been identified, you can press `Space` and a circle traced through the three points should appear. If it looks good, click inside the circle, the box will fill and then you can double-click `Space` to complete the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you made a mistake and saved the `Tank` incorrectly,** run the following command and before retrying the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_tank = trial.new_file(\"tank.pik\")\n",
    "try:\n",
    "    os.remove(fname_tank)\n",
    "    print(fname_tank, \"removed.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No tank object to remove.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = Trial(raw_video, \n",
    "              n = n, \n",
    "              t = t, \n",
    "              date = date,\n",
    "              fps = fps, \n",
    "              tank_radius = tank_radius,\n",
    "              t_start = t_start, \n",
    "              t_end = t_end )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've made it this far, nice job! You initialized a Trial object. Run the final command to save as `trial.pik`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset ##\n",
    "\n",
    "If you're not sure where you made a mistake and just need to start from the beginning, run the following to delete saved Trial and Tank objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_trial = trial.new_fname(\"trial.pik\")\n",
    "try:\n",
    "    os.remove(fname_trial)\n",
    "    print(fname_trial, \"removed.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No trial object to remove.\")\n",
    "    \n",
    "fname_tank = trial.new_fname(\"tank.pik\")\n",
    "try:\n",
    "    os.remove(fname_tank)\n",
    "    print(fname_tank, \"removed.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No tank object to remove.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking and processing\n",
    "\n",
    "## Overview\n",
    "\n",
    "In order to track and process the trial, you will now need to run another set script. This will involve the following steps:\n",
    "1. Import the relevant libraries from `cv-tracer`\n",
    "2. Re-open the appropriate `Trial` object.\n",
    "3. Enter parameters relevant to this run, and initialize a `CVTracer` object using those parameters. \n",
    "4. Run the tracking loop.\n",
    "5. Process the tracks to convert pixels to centimeters and calculate kinematic quantities like velocity, turning velocity, and acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the tracking code\n",
    "First we can import `sys` and `numpy` along with two relevant `cvtracer` class modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "import sys\n",
    "import numpy as np\n",
    "from cvt.TrAQ.Trial import Trial\n",
    "from cvt.TrAQ.CVTracer import CVTracer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will re-open the `Trial` we initialized in the last step and input tracking parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_video = trial.new_fname(\"raw.mp4\")\n",
    "# open up the Trial\n",
    "trial       = Trial(raw_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next set the start and end times for tracking. You should be able to set this to a longer time than your trial to capture the entire thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start =  0 # enter start time in seconds\n",
    "t_end   = 60 # enter   end time in seconds\n",
    "\n",
    "frame_start = int(t_start * fps)\n",
    "frame_end   = int(t_end   * fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, enter information tracking parameters. These parameters are used to identify fish in the each image of the video. `cvtracer` uses functions from the the `openCV` library to do the following:\n",
    "- handle noise by blurring pixels to smooth the image (may want to increase with higher resolution video)\n",
    "- set block sizes for thresholding\n",
    "- set the threshold offset required for contour identification (you may want to change these)\n",
    "- set the minimum and maximum areas of contours (you will need to change these to handle videos at different resolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixel_blur  =  3 # square-root of n-pixels for threshold blurring\n",
    "block_size    = 15 # contour block size\n",
    "thresh_offset = 13 # threshold offset for contour-finding\n",
    "\n",
    "min_area =  20 # minimum area for threhold detection\n",
    "max_area = 500 # maximum area for threhold detection\n",
    "\n",
    "online_viewer = True\n",
    "view_scale = 1  # scale size online viewer\n",
    "\n",
    "RGB = True # track in color, false does greyscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can initialize the `CVTracer` object using the information set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cvt         = CVTracer( trial, frame_start = frame_start, frame_end = frame_end, \n",
    "                        n_pixel_blur = n_pixel_blur, block_size = block_size, \n",
    "                        threshold_offset = int(thresh_offset), \n",
    "                        min_area = min_area, max_area = max_area, len_trail = 3, \n",
    "                        RGB = RGB, online = online_viewer, view_scale = view_scale, \n",
    "                        GPU = False ) \n",
    "\n",
    "cvt.print_title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to start tracking!\n",
    "\n",
    "Now that you have initialized the `CVTracer` you should be ready to go! Run the following loop to over each frame of the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt.set_frame(frame_start)\n",
    "for i_frame in range(cvt.frame_start, cvt.frame_end + 1):\n",
    "    # load next frame into video tracer\n",
    "    if cvt.get_frame():\n",
    "        # first remove all information from outside of tank\n",
    "        cvt.mask_tank()       \n",
    "        # detect contours in current frame\n",
    "        cvt.detect_contours()\n",
    "        # analyze contours for center and long axis\n",
    "        cvt.analyze_contours()\n",
    "        # estimate connection between last frame and current frame\n",
    "        cvt.connect_frames()\n",
    "        # store results from current frame in the trial object\n",
    "        cvt.update_trial()\n",
    "        # write frame with traces to new video file, show if online\n",
    "        cvt.draw()\n",
    "        # write frame to video output\n",
    "        cvt.write_frame()\n",
    "        # post frame to screen, may accept user input to break loop\n",
    "        if not cvt.post_frame(): break\n",
    "        # print time to terminal\n",
    "        cvt.print_current_frame()\n",
    "# put things away\n",
    "cvt.release()\n",
    "cvt.trial.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you want it to run faster and don't plan to watch, set `online_viewer = False`. If you do this, review the output video `traced.mp4`.\n",
    "\n",
    "*If you are interested* in learning more knitty-gritty details of computer vision, this is the part where it *might* be interesting to open up `cvt/TrAQ/CVTracer.py` module using the `Spyder` application that came with Anaconda. In the last cell, functions called by `cvt.<function_name>` are defined in `cvt/TrAQ/CVTracer.py` and each definition begins with  `def <function_name>(...)`. Questions are welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the results\n",
    "\n",
    "Finally, we will convert the pixel data to centimeters and calculate some kinematic quantities. The `Trial` object knows how to convert to centimeters thanks to the radius we entered when we defined the `Tank`. It can convert frames to time using the frames per second we gave upon defining the `Trial`. With these two conversions, we are able to determine quantites like velocity and acceleration and director turning velocity and acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convert pixels to centimeters\n",
    "trial.convert_pixels_to_cm()\n",
    "trial.calculate_kinematics()\n",
    "trial.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now a quick analysis\n",
    "\n",
    "So now we have some data for a single run. Using this data, let's quickly explore the resulting data in terms of distance to the wall, speed, turning, and schooling.\n",
    "\n",
    "First of all, if you're just returning to this, go ahead and load the Trial again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_video = trial.fname(\"raw.mp4\")\n",
    "# open up the Trial\n",
    "trial       = Trial(raw_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets evaluate some cuts to clean up any predictably messy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to a desired activity cut for cases \n",
    "# where fish are stopping, starting as 0 \n",
    "activity_cut = 0\n",
    "\n",
    "val_name  = ['dwall', 'speed', 'omega']\n",
    "val_range = [ [0, 55.5], [activity_cut, 80], [-25, 25] ]\n",
    "val_bins  = [   10,     10,     10  ]\n",
    "\n",
    "n_buffer_frames = 2\n",
    "\n",
    "# evaluate_cuts will determine which frames need to be excluded \n",
    "# three reasons for cuts: \n",
    "#   1. occlusions (ocut), \n",
    "#   2. speed (vcut), \n",
    "#   3. turning speed (wcut)\n",
    "# you can define the ranges of these cuts above.\n",
    "tag = trial.evaluate_cuts(n_buffer_frames = n_buffer_frames,\n",
    "                          ocut = 0,\n",
    "                          vcut = val_range[1],\n",
    "                          wcut = val_range[2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `Trial` knows which frames should be cut, we can calculate and plot statistics of the relevant quantities for individual fish. \n",
    "\n",
    "`calculate_statistics` will output plots to the trial's directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.calculate_statistics(val_name = val_name, \n",
    "                           val_range = val_range, \n",
    "                           val_bins = val_bins,\n",
    "                           ocut = True, vcut = True, wcut = True,\n",
    "                           tag = tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, while it was hidden from you, we already calculated the pairwise distances and alignments of all the fish when we evaluated the cuts. The group object has saved that information. Since this level of analysis might be interesting, let's access that data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trial.group.collect_distance_alignment(ocut = True, \n",
    "                                       vcut = True, \n",
    "                                       wcut = True)\n",
    "dist_align = np.copy(trial.group.dij_mij)\n",
    "\n",
    "# convert to degrees\n",
    "dist_align[:,1] = 180/np.pi*np.arccos(dist_align[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pair_map(dist_align, save = False):\n",
    "    plt.hist2d(dist_align[:,0], dist_align[:,1], \n",
    "               bins = [40,40], range=[[0,111],[0,180]])\n",
    "    plt.xlabel(\"pair distance (cm)\")\n",
    "    plt.ylabel(\"pair angle (deg)\")\n",
    "    plt.colorbar()\n",
    "    if save:\n",
    "        plt.savefig(trial.new_fname(\"pairs_%s.png\" % tag))\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "plot_pair_map(dist_align)\n",
    "plot_pair_map(dist_align, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
